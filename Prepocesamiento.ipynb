{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepocesamiento de texto\n",
    "En este Notebook se presenta el procesamiento de informacion realizado para implementar el proyecto \"Mex-IA: Chatbot basado en RAG enfocado al apoyo legal del ciudadano\" sometido al concurso \"Acelerando Mexico con Inteligencia Articfial\", organizado por Intel.\n",
    "\n",
    "El objetivo de este Notebook es identificar y extraer la informacion de cada uno de los articulos incluidos en el documento oficial de la constitucion Mexicana. Para lograr dicho objetivo, se optop por usar Expresiones Regulares (RE, Regular Expressions) para identificar el inicio y final de cada aritculo. Posteriormente, Se utiliza la libreria Llama Index para transformar el contenido de cada articulo en una representacion numerica atrves de la evaluacion del texto en Embedings.\n",
    "\n",
    "El contenido del Notebook se divide como sigue:\n",
    "1. Extraccion del contenido de articulos\n",
    "2. Transformacion a representacion numerica\n",
    "3. Validacion de la lectura de articulos en su representacion numerica"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Extracción del contenido de artículos\n",
    "A continuacion se implementa una funcion para procesar el contenido de cada pagina del documento de la constitucion en pdf. El objetivo de esta funcion es eliminar informacion redundante, como lo son el pie de pagina.\n",
    "\n",
    "Con esta funcion se lee cada pagina del archivo y se extrae la informacion usando expresiones regulares para detectar el principio y fin de cada articulo. Una vez extraida la informacion se almacena el contenido de cada articulo en archivos .txt, los cuales se encuentran en la carpeta [articulos](articulos)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cargamos librerias\n",
    "from PyPDF2 import PdfReader\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# funcion para eliminar el contenido inecesario del pie de cada pagina\n",
    "def clean_text(page, split_sent=None):\n",
    "    text = page.extract_text()\n",
    "    splits = re.split(r\"(\\d+\\sde\\s382)\", text)\n",
    "    out = splits[-1]\n",
    "\n",
    "    if split_sent != None:\n",
    "        aux_split = re.split(f'{split_sent}', out)\n",
    "        out = aux_split[0]\n",
    "\n",
    "    return out.strip()\n",
    "\n",
    "# extraccion del contenido de los articulos (no transitorios)\n",
    "reader = PdfReader('data/CPEUM.pdf')\n",
    "texto_completo = ''\n",
    "\n",
    "# Extraer el texto completo del PDF\n",
    "for pi in range(159):\n",
    "    if pi==158:\n",
    "        texto_completo += clean_text(page=reader.pages[pi], split_sent='Artículos Transitorios')\n",
    "    else:\n",
    "        texto_completo += clean_text(page=reader.pages[pi])\n",
    "\n",
    "articulos = re.split(r\"(Artículo\\s+\\d+o?.)\", texto_completo)\n",
    "\n",
    "# creamos archivos con el contenido del articulo\n",
    "for i in range(1, len(articulos), 2):\n",
    "    # El índice i contiene \"Artículo X\" y el índice i+1 contiene el contenido del artículo\n",
    "    titulo_articulo = articulos[i].strip()\n",
    "    print(titulo_articulo)\n",
    "    contenido_articulo = f'{articulos[i].strip()}\\n'+articulos[i + 1].strip()\n",
    "    \n",
    "    # Crear un documento con el artículo\n",
    "    with open(f'articulos/{titulo_articulo.replace(\".\", \"\")}.txt', 'w') as f:\n",
    "        f.write(contenido_articulo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Transformacion a representacion numerica\n",
    "Posteriormente se transforma la informacion extraida de cada articulo a una reresentacion numerica, ya que la tecnica RAG usada en la implementacion del modelo propuesto requiere este formato.\n",
    "\n",
    "En primer lugar se define la configuracion a usar, incluyendo el modelo de lenguaje (`gpt-4o-mini`) y el tipo de embeding (`text-embedding-3-small`). Note que esta etapa del proyecto requiere de un API key de OPEN AI para usar los modelos preentrenados, para mas informacion consulte [link](link...). Tambien es necesario crear una sesion de Chroma DB para alamcenar el resultado de la transformacion numerica. Este paso es fundamental, ya que la evaluacion de la base de datos consume recursos del API, por lo cual es importante alamcenar el resultado con el fin de evitar costos incesesarios cada vez que se requiera usar el modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# se configura el modelo de lenguaje y embedding\n",
    "from llama_index.llms.openai import OpenAI\n",
    "from llama_index.core import VectorStoreIndex, Settings\n",
    "from llama_index.embeddings.openai import OpenAIEmbedding\n",
    "import os\n",
    "\n",
    "# api key\n",
    "key = ''\n",
    "with open('openai_key.txt', 'r') as t:\n",
    "    key = t.read()\n",
    "os.environ[\"OPENAI_API_KEY\"] = key\n",
    "\n",
    "# configuracion del modelo y embeding\n",
    "embed_model = OpenAIEmbedding(model=\"text-embedding-3-small\")\n",
    "Settings.embed_model = embed_model\n",
    "Settings.llm = OpenAI(model=\"gpt-4o-mini\")\n",
    "\n",
    "# creamos sesion para guardar Vector Store Index\n",
    "import chromadb\n",
    "from llama_index.vector_stores.chroma import ChromaVectorStore\n",
    "from llama_index.core import StorageContext\n",
    "\n",
    "#  se inicializa cliente y coleccion\n",
    "db = chromadb.PersistentClient(path=\"./index_data\")\n",
    "chroma_collection = db.get_or_create_collection(\"quickstart\")\n",
    "\n",
    "# asignamos ubicacion del vector store\n",
    "vector_store = ChromaVectorStore(chroma_collection=chroma_collection)\n",
    "storage_context = StorageContext.from_defaults(vector_store=vector_store)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con la configuracion definida previmante, se transforma el contenido de cada articulo en una representacion numerica y se alamcena el resultado en la carpeta [index_data](index_data)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import Document\n",
    "\n",
    "# Cargamos los documentos de los articulos\n",
    "import os\n",
    "data_path = 'articulos'\n",
    "files = os.listdir(data_path)\n",
    "documents = [] # lista de documentos\n",
    "\n",
    "for fi in files:\n",
    "    with open(f'{data_path}/{fi}', 'r') as t:\n",
    "        auxd = Document(text=t.read(), metadata={\"nombre\":f\"{fi.split('.')[0]}\"})\n",
    "        documents.append(auxd)\n",
    "\n",
    "# se crean los index de los documentos y se almacenan\n",
    "index = VectorStoreIndex.from_documents(\n",
    "    documents, storage_context=storage_context\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Validacion de la lectura de articulos en su representacion numerica\n",
    "Por ultimo, se muestra el proceso necesario para recuperar la representacion numerica del contenido de cada articulo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# para volver a cargar los index\n",
    "from llama_index.llms.openai import OpenAI\n",
    "from llama_index.core import VectorStoreIndex, Settings\n",
    "from llama_index.embeddings.openai import OpenAIEmbedding\n",
    "import os\n",
    "import chromadb\n",
    "from llama_index.vector_stores.chroma import ChromaVectorStore\n",
    "from llama_index.core import StorageContext\n",
    "\n",
    "# api key\n",
    "key = ''\n",
    "with open('openai_key.txt', 'r') as t:\n",
    "    key = t.read()\n",
    "os.environ[\"OPENAI_API_KEY\"] = key\n",
    "\n",
    "# configuracion del modelo y embeding\n",
    "embed_model = OpenAIEmbedding(model=\"text-embedding-3-small\")\n",
    "Settings.embed_model = embed_model\n",
    "Settings.llm = OpenAI(model=\"gpt-4o-mini\")\n",
    "\n",
    "\n",
    "# inicia el cliente\n",
    "db = chromadb.PersistentClient(path=\"./index_data\")\n",
    "chroma_collection = db.get_or_create_collection(\"quickstart\")\n",
    "vector_store = ChromaVectorStore(chroma_collection=chroma_collection)\n",
    "storage_context = StorageContext.from_defaults(vector_store=vector_store)\n",
    "\n",
    "# lee el index del contenido almacenado\n",
    "index = VectorStoreIndex.from_vector_store(\n",
    "    vector_store, storage_context=storage_context\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finalmente se muestra un ejemplo para verificar que el contenido de cada articulo se almaceno correctamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ejemplo usando metadata\n",
    "import pprint\n",
    "from llama_index.core.retrievers import VectorIndexRetriever\n",
    "\n",
    "# RAG para las top 2 coincidencias mas similares\n",
    "retriever = VectorIndexRetriever(\n",
    "    index=index,\n",
    "    similarity_top_k=2,\n",
    ")\n",
    "\n",
    "# pregunta original\n",
    "query = \"los mexicanos tienen derecho a la educacion?\"\n",
    "nodes = retriever.retrieve(query)\n",
    "\n",
    "# accede a la informacion del retrieve dado el query\n",
    "docs = ''\n",
    "for ni in nodes:\n",
    "    aux_dic = dict(ni)\n",
    "    print(aux_dic)\n",
    "    docs += f\"Nombre del documento: {aux_dic['node'].metadata['nombre']}\\Contenido: {aux_dic['node'].text} \\n\"\n",
    "pprint.pprint(docs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
